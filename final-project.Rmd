---
title: "Exploring the Expedia Recommendation Algorithm"
author: 'Group 35: Max Ming Yi Koh (1007972785) and Kevin Le (1007952805)'
date: "March 31, 2022"
output:
  beamer_presentation:
    theme: Pittsburgh
    colortheme: orchid
    fonttheme: structurebold
    slide_level: 2
  pdf_document: default
classoption: aspectratio=169
fontsize: 11pt
urlcolor: blue
---


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# echo=FALSE will stop the code chunk from appearing in the knit document
# warning=FALSE and message=FALSE will stop R messages from appearing in the knit document
library(tidyverse)
library(dplyr)
# here is the data for this project
expedia_data <- read_csv("ExpediaSearchData.csv")
# see the Project Overview page for more information: 
# https://q.utoronto.ca/courses/235890/pages/project-overview
```

## General Motivations and Dataset Description

* Expedia generates revenue by reselling bookings (purchased in bulks at discounted pricing) or charging commissions from hoteliers$^{[1]}$.

* Thus, an effective recommendation algorithm that recognizes consumer needs is crucial to improve user experience and optimize the bottom line of the business.

* We formulate 3 research questions that help answer the following questions:
  1. How effective is Expedia's recommendation algorithm? 
  2. What are some factors that affect purchasing decisions of consumers? 

* The investigation uses a dataset of 1,000 user searches along with certain variables related to users or the top 3 recommended properties during the period of June $1^{st}$, 2021 and July $31^{st}$, 2021.

* Unless stated otherwise, the sample of this research consists of these 1,000 consumer searches while the population of this research consists of all users that made an Expedia search during the period of June $1^{st}$, 2021 and July $31^{st}$, 2021.

## Data Summary
Below is a table of variables used in all 3 research problems. Note that {n} is a placeholder for integers 1, 2, or 3. 
 
| Variable      	| Description                                                                                  	|
|-----------------|-----------------------------------------------------------------------------------------------|
| is_trans{n}   	|  whether the consumer transacted the n-th displayed property within 180 minutes of the search |
| is_drr{n}     	|  whether the n-th displayed property is discounted                                            |
| num_clicks{n} 	|  number of clicks for the n-th displayed property within 180 minutes of the search            |
| checkin_date  	|  stay start date                                                                              |
| checkout_date 	|  stay end date                                                                                |
| adult_count   	|  number of adults on the trip                                                                 |
| child_count   	|  number of children on the trip                                                               |


## Research Question 1 - Introduction
**Research Question**: What is the proportion of consumers during June $1^{st}$, 2021 and July $31^{st}$, 2021 that purchase one of the top 3 recommended properties within 180 minutes of their search? 

**Research Motivation**: 

* The proportion of users who purchase a top 3 recommended property is a good metric to measure the effectiveness of Expedia's recommendation algorithm. 

* For instance, a higher proportion may imply the algorithm is effective at recognizing user needs while a lower proportion may imply the algorithm is less effective at recognizing user needs. 

## Research Question 1 - Data Wrangling  
* We applied the `select()` function to obtain the required variables, namely is_trans1, is_trans2 and is_trans3. 

* Using is_trans1, is_trans2 and is_trans3 columns, we applied the `mutate()` function to create a new logical variable named trans_made which indicates whether any transactions were made by the user.

* trans_made is set to TRUE if a transaction is made within 180 minutes of a user search and FALSE if a transaction is not made within 180 minutes of a user search. 

## Research Question 1 - Data Visualization
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=2.5, fig.width=3.5, fig.align='center'}
expedia_data_q1 <- expedia_data %>% 
  select(is_trans1, is_trans2, is_trans3) %>% 
  mutate(is_trans1 = ifelse(!is.na(is_trans1) & is_trans1 == 1, 1, 0),
         is_trans1 = ifelse(!is.na(is_trans1) & is_trans1 == 1, 1, 0),
         is_trans1 = ifelse(!is.na(is_trans1) & is_trans1 == 1, 1, 0), 
         trans_made = ifelse(is_trans1 + is_trans2 + is_trans3 > 0, TRUE, FALSE)
  ) 

expedia_data_q1 %>%  
  ggplot(aes(x=trans_made)) + 
  geom_bar(color="black", fill="gray") + 
  labs(x="Transaction made by users for any \n of top 3 recommended properties",
       y="Count", 
       title="Number of users who transacted \nor have not transacted top 3 \nrecommended properties out of \n1,000 total users")
```

This figure shows that 9 out of 1,000 consumers in the sample purchase a top 3 search result recommended by Expedia's searching algorithm. 

## Research Question 1 - Statistical Analysis
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=4, fig.align='left', results="hide"}
set.seed(15) 
n <- 3000
sample_means <- rep(NA, 3000)

for (i in 1:n) {
  sample <- expedia_data_q1 %>% sample_n(size=1000, replace=TRUE)
  sample_means[i] <- as.numeric(sample %>% summarize(mean(trans_made)))
}

sample_means <- tibble(trans_proportion = sample_means) 
confidence_interval <- quantile(sample_means$trans_proportion, c(0.025, 0.975))
```

* We assume that the sample is representative of the population in order to perform bootstrapping. 

* By resampling from the sample of 1,000 users for 3,000 repetitions and choosing a 95% confidence level, we find the confidence interval for the proportion of users during June $1^{st}$, 2021 and July $31^{st}$, 2021 who purchased a top 3 recommended property is (`r confidence_interval[1]`, `r confidence_interval[2]`).
  
* A confidence level 95% means that 95% of confidence interval generated in a similar manner (i.e. resampling from the sample of 1,000 user data 3,000 times) will capture the true proportion of consumers during June $1^{st}$, 2021 and July $31^{st}$, 2021 who purchased a top 3 recommended property.

* The width of the confidence interval (i.e. $0.015 - 0.003 = 0.012$) is very narrow. So, we expect the true true proportion to be very similar to the estimate made. 

## Research Question 2 - Introduction
**Research Question**: Are discounted properties during the period of June $1^{st}$, 2021 and July $31^{st}$, 2021 more likely to result in more clicks within 180 minutes? 

**Hypothesis:** 

$H_0: \mu_{no\ discount} - \mu_{discount} = 0$

$H_1: \mu_{no\ discount} - \mu_{discount} \neq 0$ 

where $\mu_{no\ discount}$ and $\mu_{discount}$ are the mean number of clicks for non-discounted and discounted properties respectively during June $1^{st}$, 2021 and July $31^{st}$, 2021. 

**Research Motivation**: 

* The population of interest consists of all properties listed during June $1^{st}$, 2021 and July $31^{st}$, 2021. 

* Hypothetically, if users are more interested in discounted listings, it may be in Expedia's interest to discount more listings to attract more consumers. 

## Research Question 2 - Data Wrangling  
* We applied the `select()` function to obtain the required variables, namely num_clicks1, num_clicks2, num_clicks3, is_drr1, is_drr2 and is_drr3. 

* To tidy the data (due to change in population), we ran a for loop to reshape the tibble to have rows which represent listings instead of user search results. The new tibble has variables num_clicks and is_drr. 

* num_clicks represents the number of clicks received by the property within 180 minutes of the search. 
  
* is_drr represents whether the listed property is discounted. 

* We applied the `group_by()` and `summarise` functions to obtain the mean number of clicks for discounted and non-discounted listings. 

## Research Question 2 - Visualization
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=4, fig.align='center'}
untidy_expedia_data_q2 <- expedia_data %>% 
  select(num_clicks1, is_drr1, num_clicks2, is_drr2, num_clicks3, is_drr3)

expedia_data_q2 <- tibble(num_clicks=c(NA), is_drr=c(NA))
n <- nrow(untidy_expedia_data_q2)

for (i in 1:n) {
  expedia_data_q2 <- add_row(expedia_data_q2, 
                             num_clicks = as.numeric(untidy_expedia_data_q2[i, "num_clicks1"]),
                             is_drr = as.numeric(untidy_expedia_data_q2[i, "is_drr1"]))
  expedia_data_q2 <- add_row(expedia_data_q2, 
                             num_clicks = as.numeric(untidy_expedia_data_q2[i, "num_clicks2"]),
                             is_drr = as.numeric(untidy_expedia_data_q2[i, "is_drr2"]))
  expedia_data_q2 <- add_row(expedia_data_q2, 
                             num_clicks = as.numeric(untidy_expedia_data_q2[i, "num_clicks2"]),
                             is_drr = as.numeric(untidy_expedia_data_q2[i, "is_drr2"]))
}

expedia_data_q2 <- expedia_data_q2 %>% 
  filter(!is.na(num_clicks) & !is.na(is_drr)) %>% 
  mutate(is_drr = ifelse(is_drr == 1, TRUE, FALSE))

expedia_data_q2_summary <- expedia_data_q2 %>% 
  group_by(is_drr) %>% 
  summarise(mean_num_clicks=mean(num_clicks))

expedia_data_q2_summary %>% 
  ggplot(aes(x=is_drr, y=mean_num_clicks)) + 
  geom_bar(stat="identity") + 
  labs(x="Property discounted",
       y="Average number of clicks",
       title="Average number of clicks for discounted \n and non-discounted top 3 properties")
```

## Research Question 2 - Statistical Analysis
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=4, fig.align='left', results="hide"}
test_stat <- expedia_data_q2_summary %>%  
  summarize(test_stat=diff(mean_num_clicks)) %>%  
  as.numeric()

set.seed(15) 

n <- 5000
simulated_values <- rep(NA, nrow(expedia_data_q2))

for (i in 1:n) {
  simdata <- expedia_data_q2 %>% 
    mutate(is_drr = sample(is_drr)) 
  
  simulated_values[i] <- simdata %>% 
    group_by(is_drr) %>% 
    summarize(mean_num_clicks=mean(num_clicks)) %>%  
    summarize(mean_clicks_diff = diff(mean_num_clicks)) %>%  
    as.numeric()
}

simulated_values <- tibble(mean_clicks_diff = simulated_values) 

more_extreme_simulated_values <- simulated_values %>% 
  filter(abs(mean_clicks_diff) >= abs(test_stat)) %>%  
  summarize(size = n())

p_value <- as.numeric(more_extreme_simulated_values) / n
p_value
```

* The calculated test statistic from the dataset for the difference between the mean number of clicks for discounted and non-discounted properties is `r round(test_stat, digits=4)`. 

* This means that within the samples, discounted properties get `r -round(test_stat, digits=4)` less clicks than non-discounted properties on average. 

* After running 5,000 simulations under the assumption that the null hypothesis is true, the p-value is found to be `r round(p_value, digits=4)`. 

* Since the p-value is between 0.01 and 0.05, there is moderate evidence against the null hypothesis which states that the mean number of clicks for discounted and non-discounted properties is the same. 

* The implication of this result will be further discussed in the conclusion section.

## Research Question 3 - Introduction
**Research Question**: Do the number of adults and children on a trip affect the length of
travel?

**Hypothesis**: 

$H_0: \beta_1 = 0 \text { OR } \beta_2 = 0 \text{ OR }... \  \beta_n = 0$ 

$H_1: \beta_1 \neq 0 \text{ AND } \beta_2 \neq 0 \text{ AND }... \  \beta_n \neq 0$ 

where $\beta_1, \ \beta_2, \ ...\ , \ \beta_n$ are slope coefficients for the linear regression model where the predictors are the number of children and adults and the response is the length of travel. 

**Research Motivation**: 

* If a correlation exists between the type and number of travelers and length of travel, Expedia may want to consider this correlation when booking properties in bulk.

* For instance, larger properties which can fit more people may be booking for longer interval of time if the correlation is found to be positive. 

## Research Question 3 - Data Wrangling  

* We applied the `select()` function to obtain the required variables, namely adult_count, child_count, checkin_date, checkout_date. 

* We applied the `mutate()` function to create a new variable called travel_length. 

    + travel_length represents the time difference between checkout_date and checkin_date in days. 

* We applied the `select()` function to select the required variables, namely adult_count, child_count and travel_length. 

* To perform linear regression, we applied the `rowid_to_column()` function to add a unique identifier to each row in the tibble. 

## Research Question 3 - Visualization
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=4, fig.align='center'}
expedia_data_q3 <- expedia_data %>%  
  select(adult_count, child_count, checkin_date, checkout_date) %>%  
  filter(!is.na(checkin_date) & !is.na(checkout_date)) %>%  
  mutate(travel_length = as.numeric(checkout_date - checkin_date)) %>%  
  select(adult_count, child_count, travel_length) %>%  
  rowid_to_column()

expedia_data_q3 %>% ggplot(aes(x=adult_count, y=travel_length)) + 
  geom_point() + 
  geom_smooth(se=FALSE, method="lm") + 
  labs(x="Number of adults",
       y="Average length of travel (days)",
       title="Number of adults versus \naverage length of travel") + 
  theme_minimal() + 
  scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10))
```


## Research Question 3 - Statistical Analysis
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=4, fig.align='left', results="hide"}
set.seed(15) 
n <- nrow(expedia_data_q3)
training_indices <- sample(1:n, size=round(0.8 * n))
glimpse(expedia_data_q3)

train <- expedia_data_q3 %>% filter(rowid %in% training_indices)
y_train <- train$travel_length
test <- expedia_data_q3 %>% filter(!(rowid %in% training_indices)) 
y_test <- test$travel_length

mod1_train <- lm(travel_length ~ adult_count, data = train) 
mod2_train <- lm(travel_length ~ child_count, data = train) 
mod3_train <- lm(travel_length ~ adult_count + child_count, data = train) 
mod4_train <- lm(travel_length ~ adult_count * child_count, data = train) 

yhat_mod1_test <- predict(mod1_train, newdata = test) 
yhat_mod2_test <- predict(mod2_train, newdata = test) 
yhat_mod3_test <- predict(mod3_train, newdata = test) 
yhat_mod4_test <- predict(mod4_train, newdata = test) 

yhat_mod1_train <- predict(mod1_train, newdata = train)
yhat_mod2_train <- predict(mod2_train, newdata = train) 
yhat_mod3_train <- predict(mod3_train, newdata = train) 
yhat_mod4_train <- predict(mod4_train, newdata = train) 

mod1_test_RMSE <- sqrt(sum((y_test - yhat_mod1_test)^2 / nrow(test)))
mod2_test_RMSE <- sqrt(sum((y_test - yhat_mod2_test)^2 / nrow(test)))
mod3_test_RMSE <- sqrt(sum((y_test - yhat_mod3_test)^2 / nrow(test)))
mod4_test_RMSE <- sqrt(sum((y_test - yhat_mod4_test)^2 / nrow(test)))

mod1_train_RMSE <- sqrt(sum((y_train - yhat_mod1_train)^2 / nrow(train)))
mod2_train_RMSE <- sqrt(sum((y_train - yhat_mod2_train)^2 / nrow(train)))
mod3_train_RMSE <- sqrt(sum((y_train - yhat_mod3_train)^2 / nrow(train)))
mod4_train_RMSE <- sqrt(sum((y_train - yhat_mod4_train)^2 / nrow(train)))

model_comparison_table <- tibble(Model = c("1", "2", "3", "4"), 
                                 RMSE_testdata = c(mod1_test_RMSE, mod2_test_RMSE,
                                                   mod3_test_RMSE, mod4_test_RMSE),
                                 RMSE_traindata = c(mod1_train_RMSE, mod2_train_RMSE,
                                                    mod3_train_RMSE, mod4_train_RMSE),
                                 ratio_of_RMSEs = RMSE_testdata / RMSE_traindata)

model_comparison_table
summary(mod1_train)$r.squared
summary(mod2_train)$r.squared
summary(mod3_train)$r.squared
summary(mod4_train)$r.squared
coefficients <- summary(mod1_train)$coefficients
```

* After trying several linear regression models (e.g. simple, multiple regression with or without interaction), we find that a single linear regression "best" explains the association between number and type of travelers and length of the trip. 

* By picking the "best" model based on prediction accuracy, low signs of overfitting and simplicity, we find it is sufficient to only consider how many adults are on a trip to predict the length of the trip. 

* The extremely small p-value of `r round(5.546797e-04, digits=6)` suggests there is very strong evidence against the null hypothesis that there is no relationship between the number of adults on a trip and the length of a trip. Thus, we reject the null hypothesis. 

* The calculated slope of `r round(0.4257908, digits=4)` implies that for each additional adult, the length of trip increases by `r round(0.4257908, digits=4)` days on average. 

* However, the $R^2$ value of `r round(summary(mod1_train)$r.squared,4)` for the linear regression model implies only `r round(summary(mod1_train)$r.squared,4) * 100`% of variability in the length of trip is accounted by the number of adults on the trip. 

## Limitations 

* We assume that data filled in by users is accurate. Inaccurate data entries (e.g. typos) may skew the statistical results. 

* We assume that the sample is representative of the population. Otherwise, statistical models (especially bootstrapping) will not yield accurate results. 

* For research questions 1 and 2, is_trans{n} and num_clicks{n} only measure user events like transaction or clicks for 180 minutes within the search. As a result, this limitation carries over to the results discussed. 

* For research question 2, transactions are a better metric of consumer interest compared to clicks received by a listing. However, only 9 properties are transacted out of the 3,000 properties. So, we used the number of clicks as the metric. 

* For research question 3, we intended to research how the number of adults, children and infants affect the length of travel. However, only 9 data points had infants in their travel group. So, we removed the number of infants as a potential predictor. 

## Overall Conclusion - Looking Ahead Part 1
Here are some closing thoughts for each research question.

For the **research question 1**, 

* The 95% confidence interval for the proportion of top 3 recommended listings transacted is (`r confidence_interval[1]`, `r confidence_interval[2]`). 
* The bounds of the interval are low which implies the recommendation algorithm has room for improvement. 

* We recommend Expedia to invest in research and development of recommendation algorithms can improve the profitability of the business. 

## Overall Conclusion - Looking Ahead Part 2
For the **research question 2**, 

* It was found that there is weak evidence against the null hypothesis that the mean number of clicks for discounted and non-discounted properties is the same. 

* We recommend Expedia to perform A/B testing with 1 variation of website where the difference lies in the number of discounted properties$^{[2]}$.

* This allows Expedia to find out how user consumption behaviours change based on change in the number of discounted properties.  

* This may lead to developing new marketing strategies in terms of discounting more or less properties to maximize profit. 

## Overall Conclusion - Looking Ahead Part 3
For the **research question 3**, 

* It is found that as the number of adults increases, the length of travel increases. 

* Expedia can consider the linear regression model when purchases properties in bulk or advising hoteliers regarding the expected intervals of booking. For instance, if a property has many rooms, booking it for a longer interval will prevent cases where the property is not transacted as it does not suit consumer needs.

* However, the low $R^2$ value of `r summary(mod1_train)$r.squared` implies there are other variables that explain the variability in travel length. 

* To get a more "complete" model, Expedia may choose to continue to explore how other variables (including variables that do not appear in the current dataset) affect length of travel. 

## Citations 

1. https://www.nasdaq.com/articles/how-expedia-makes-most-its-money-2017-08-28

2. https://vwo.com/ab-testing/
